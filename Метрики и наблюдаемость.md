# Метрики и наблюдаемость

Observability (наблюдаемость) - это способность понять внутреннее состояние системы, анализируя её внешние выходные данные. В отличие от мониторинга, который отвечает на вопрос "работает ли система?", observability помогает понять "почему система работает именно так?".

## Three Pillars of Observability

### 1. Metrics (Метрики)

Числовые измерения системы во времени.

**Примеры:**
- CPU usage: 45%
- Request rate: 1000 req/sec
- Response time: 150ms

**Характеристики:**
- Низкая детализация (агрегированные данные)
- Малый объем данных
- Идеальны для алертов и дашбордов
- Легко хранить длительное время

### 2. Logs (Логи)

Текстовые записи о событиях в системе.

**Примеры:**
```json
{
  "timestamp": "2024-01-15T10:30:45Z",
  "level": "error",
  "message": "Failed to connect to database",
  "error": "connection refused",
  "user_id": "12345"
}
```

**Характеристики:**
- Высокая детализация
- Большой объем данных
- Полезны для отладки конкретных проблем
- Дорого хранить долго

### 3. Traces (Трассировки)

Путь запроса через распределенную систему.

**Пример trace:**
```
Request /api/users/123
├─ API Gateway [50ms]
├─ Auth Service [20ms]
├─ User Service [100ms]
│  ├─ Database Query [80ms]
│  └─ Cache Check [5ms]
└─ Response [10ms]
Total: 180ms
```

**Характеристики:**
- Показывают взаимодействие между сервисами
- Помогают найти bottleneck'и
- Средний объем данных
- Критичны для микросервисов

## Метрики: RED Method

RED метод - это набор ключевых метрик для сервисов, ориентированных на запросы (request-driven).

### Rate (Частота запросов)

Количество запросов в секунду.

```go
package main

import (
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
)

var (
    requestsTotal = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "http_requests_total",
            Help: "Total number of HTTP requests",
        },
        []string{"method", "endpoint"},
    )
)

func handleRequest(method, endpoint string) {
    // Инкрементируем счетчик
    requestsTotal.WithLabelValues(method, endpoint).Inc()

    // ... обработка запроса
}
```

### Errors (Ошибки)

Количество или процент неуспешных запросов.

```go
var (
    requestsTotal = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "http_requests_total",
            Help: "Total HTTP requests",
        },
        []string{"method", "endpoint", "status"},
    )
)

func handleRequest(method, endpoint string, statusCode int) {
    status := "success"
    if statusCode >= 400 {
        status = "error"
    }

    requestsTotal.WithLabelValues(method, endpoint, status).Inc()
}

// Error rate: rate(http_requests_total{status="error"}[5m])
//             /
//             rate(http_requests_total[5m])
```

### Duration (Длительность)

Время обработки запросов.

```go
var (
    requestDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name: "http_request_duration_seconds",
            Help: "HTTP request duration in seconds",
            Buckets: prometheus.DefBuckets, // [0.005, 0.01, 0.025, 0.05, ...]
        },
        []string{"method", "endpoint"},
    )
)

func handleRequest(method, endpoint string) {
    start := time.Now()

    // ... обработка запроса

    duration := time.Since(start).Seconds()
    requestDuration.WithLabelValues(method, endpoint).Observe(duration)
}
```

**Почему RED метрики важны:**
- **Rate** показывает нагрузку на систему
- **Errors** показывает надежность
- **Duration** показывает производительность

## Метрики: USE Method

USE метод - для ресурсов (CPU, память, диск, сеть).

### Utilization (Утилизация)

Процент времени, когда ресурс занят.

```go
// Метрика CPU utilization (обычно собирается через node_exporter)
// cpu_usage_percent = 100 - (idle_time / total_time * 100)
```

**Примеры:**
- CPU: 75% utilization
- Memory: 8GB used / 16GB total = 50%
- Disk: 70% I/O utilization

### Saturation (Насыщение)

Очередь работы, которую ресурс не может обработать немедленно.

```go
var (
    queueSize = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "worker_queue_size",
            Help: "Number of tasks waiting in queue",
        },
    )
)

func addToQueue(task Task) {
    queue = append(queue, task)
    queueSize.Set(float64(len(queue)))
}
```

**Примеры:**
- Load average (Linux): 2.5 на 4-ядерном CPU
- Disk I/O queue length: 10 операций ждут
- TCP retransmits: признак насыщения сети

### Errors (Ошибки)

Ошибки ресурсов.

**Примеры:**
- Disk read errors
- Network packet drops
- Memory allocation failures (OOM)

## SLI, SLO, SLA

### SLI (Service Level Indicator)

Метрика, которая измеряет уровень сервиса.

**Примеры SLI:**
- Availability: 99.9% запросов получили ответ
- Latency: 95% запросов < 200ms
- Error rate: < 0.1% ошибок

```go
// Пример вычисления SLI для latency
// SLI: "95% запросов должны обрабатываться < 200ms"

var (
    requestDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name: "http_request_duration_seconds",
            Help: "HTTP request duration",
            Buckets: []float64{0.05, 0.1, 0.2, 0.5, 1.0, 2.0}, // включая 200ms = 0.2s
        },
        []string{"endpoint"},
    )
)

// PromQL для проверки SLI:
// histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) < 0.2
```

### SLO (Service Level Objective)

Целевое значение SLI, которое обещает команда.

**Примеры SLO:**
- "API должен быть доступен 99.9% времени (43 минуты downtime в месяц)"
- "95% запросов должны обрабатываться < 200ms"
- "Ошибок должно быть < 0.1%"

**Error Budget (бюджет ошибок):**
Если SLO = 99.9%, то Error Budget = 0.1%

```
Monthly requests: 10,000,000
Error budget: 10,000,000 * 0.001 = 10,000 failed requests
```

Если бюджет израсходован - останавливаются релизы, фокус на надежности.

### SLA (Service Level Agreement)

Договор с клиентом с последствиями за нарушение SLO.

**Пример SLA:**
- "API будет доступен 99.9% времени"
- "Если availability < 99.9% - возврат 10% стоимости"
- "Если availability < 99% - возврат 25% стоимости"

**Важно:** SLO должен быть строже SLA, чтобы иметь буфер.

```
SLA: 99.5% (обещано клиентам)
SLO: 99.9% (внутренняя цель команды)
```

## Практический пример: Мониторинг Go-сервиса

```go
package main

import (
    "log"
    "net/http"
    "time"

    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
    "github.com/prometheus/client_golang/prometheus/promhttp"
)

var (
    // RED метрики
    requestsTotal = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "api_requests_total",
            Help: "Total API requests",
        },
        []string{"method", "endpoint", "status"},
    )

    requestDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "api_request_duration_seconds",
            Help:    "API request duration",
            Buckets: []float64{0.001, 0.01, 0.05, 0.1, 0.5, 1, 2, 5},
        },
        []string{"method", "endpoint"},
    )

    // USE метрики (пример для очереди)
    queueSize = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "worker_queue_size",
            Help: "Current queue size",
        },
    )

    activeWorkers = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "workers_active",
            Help: "Number of active workers",
        },
    )
)

// Middleware для сбора метрик
func metricsMiddleware(next http.HandlerFunc) http.HandlerFunc {
    return func(w http.ResponseWriter, r *http.Request) {
        start := time.Now()

        // Wrapper для захвата status code
        wrapped := &responseWriter{ResponseWriter: w, statusCode: http.StatusOK}

        next(wrapped, r)

        duration := time.Since(start).Seconds()

        // Записываем метрики
        status := "success"
        if wrapped.statusCode >= 400 {
            status = "error"
        }

        requestsTotal.WithLabelValues(
            r.Method,
            r.URL.Path,
            status,
        ).Inc()

        requestDuration.WithLabelValues(
            r.Method,
            r.URL.Path,
        ).Observe(duration)
    }
}

type responseWriter struct {
    http.ResponseWriter
    statusCode int
}

func (rw *responseWriter) WriteHeader(code int) {
    rw.statusCode = code
    rw.ResponseWriter.WriteHeader(code)
}

func main() {
    // Endpoint для Prometheus
    http.Handle("/metrics", promhttp.Handler())

    // API endpoints
    http.HandleFunc("/api/users", metricsMiddleware(handleUsers))
    http.HandleFunc("/api/health", metricsMiddleware(handleHealth))

    log.Println("Server starting on :8080")
    log.Fatal(http.ListenAndServe(":8080", nil))
}

func handleUsers(w http.ResponseWriter, r *http.Request) {
    // Симулируем работу
    time.Sleep(50 * time.Millisecond)
    w.Write([]byte(`{"users": []}`))
}

func handleHealth(w http.ResponseWriter, r *http.Request) {
    w.Write([]byte("OK"))
}
```

## Алерты на основе метрик

```yaml
# prometheus_alerts.yml
groups:
  - name: api_alerts
    interval: 30s
    rules:
      # High error rate
      - alert: HighErrorRate
        expr: |
          rate(api_requests_total{status="error"}[5m])
          /
          rate(api_requests_total[5m]) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }}"

      # Slow requests (p95 latency)
      - alert: SlowRequests
        expr: |
          histogram_quantile(0.95,
            rate(api_request_duration_seconds_bucket[5m])
          ) > 1.0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "95th percentile latency > 1s"

      # Service down
      - alert: ServiceDown
        expr: up{job="api-service"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Service is down"
```

## Best Practices

1. ✅ **Начните с RED метрик** для всех API endpoints
2. ✅ **Используйте USE метрики** для ресурсов (CPU, память, диск)
3. ✅ **Определите SLI/SLO** для критичных сервисов
4. ✅ **Используйте labels разумно** (не создавайте высокую cardinality)
5. ✅ **Алерты на симптомы**, а не на причины (alerting на error rate, а не на CPU)
6. ✅ **Dashboard для людей**, а не для красоты
7. ❌ **Не собирайте метрики "на всякий случай"** - только те, что используете
8. ❌ **Не делайте слишком много labels** - это увеличивает cardinality

## Типичные ошибки

### Ошибка 1: Высокая cardinality labels

```go
// ❌ Плохо - user_id создает миллионы уникальных метрик
requestsTotal.WithLabelValues(userID, endpoint).Inc()

// ✅ Хорошо - ограниченное количество labels
requestsTotal.WithLabelValues(endpoint, statusCode).Inc()
```

### Ошибка 2: Алерты на cause, а не на symptom

```yaml
# ❌ Плохо - алерт на причину
- alert: HighCPU
  expr: cpu_usage > 80%

# ✅ Хорошо - алерт на симптом
- alert: SlowRequests
  expr: p95_latency > 1s
```

## Вопросы с собеседований

**Вопрос:** В чем разница между мониторингом и observability?

**Ответ:**
- **Мониторинг** - это сбор предопределенных метрик и проверка известных проблем ("система работает?")
- **Observability** - это способность исследовать систему и находить unknown unknowns ("почему система работает так?")
- Мониторинг - подмножество observability

**Вопрос:** Что важнее: availability или latency?

**Ответ:** Зависит от контекста:
- Для критичных систем (платежи) - availability важнее
- Для пользовательских интерфейсов - latency важнее (медленный = недоступный)
- В идеале нужен баланс, определяемый SLO

**Вопрос:** Что такое golden signals?

**Ответ:** Это 4 ключевых метрики из Google SRE:
1. Latency - время ответа
2. Traffic - количество запросов
3. Errors - процент ошибок
4. Saturation - насыщение ресурсов

По сути это RED + Saturation.

**Вопрос:** Как выбрать SLO?

**Ответ:**
1. Понять ожидания пользователей (что для них "быстро" и "надежно")
2. Посмотреть текущие показатели
3. Начать консервативно (99% лучше чем 99.999%)
4. Итеративно улучшать
5. SLO должен быть достижим, но амбициозен

## Связанные темы

- [[Prometheus]]
- [[Grafana]]
- [[Логирование - Best practices]]
- [[CI-CD - Основные концепции]]
- [[Микросервисная архитектура]]
